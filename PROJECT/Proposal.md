Henry Phạm   
Professor Rawski  
LING 165 \- Intro to Natural Language Processing  
April 20th, 2025  
Text Normalization for Speech or Chatbots Using Finite-State Transducers  
Text normalization is a critical preprocessing step in Natural Language Processing (NLP) applications, particularly for speech recognition and conversational AI systems. It is the conversion of noisy, informal, or non-standard input into a more standardized format that is easier to process by downstream systems. In speech recognition or chatbot contexts, it is the translation of slang, abbreviations, or unconventional spellings into standard language. Within this project, I will be undertaking the task of creating a Finite-State Transducer (FST) to normalize Gen Z slang into standard English. It is hoped to render inputs by younger users (e.g., "fr fr no cap") more understandable to NLP software that may not otherwise be capable of processing similar phrases. System robustness within real-world conversational settings will be enhanced.   
While a full review of the literature is not necessary, I have read current work in text normalization, particularly rule-based and statistical modeling. FSTs have been widely used in low-latency applications, e.g., speech recognizers, due to their efficiency and ease of interpretation. Google's speech recognition text normalization pipeline (Gorman and Sproat, 2021\) demonstrates the use of FSTs for converting spoken-form text to written-form text. My project adapts the same principles to normalize slang in user inputs.

The primary dataset for the project will be Hugging Face's Gen Z Slang Dataset. It has hundreds of slang terms, their meanings, and example uses in sentence form. To get this dataset ready for FST development, I will first clean and structure the data. This will entail lowercasing all entries, removing any unnecessary punctuation, and standardizing the format so that every entry clearly maps a slang term (or phrase) to its standardized form. I will also remove duplicates and filter out slang that cannot be mapped directly to a single standardized phrase without additional context. One of the key preprocessing steps will be the classification of slang into types such as abbreviations ("wyd" → "what are you doing"), semantic shift ("cap" → "lie"), and phonetic spellings ("finna" → "going to"). These types will be utilized to specify reusable FST subgraphs. Since some expressions are context-dependent, I may manually select a subset of the dataset for high-precision rule construction and evaluation. I will split the dataset into training, validation, and test sets to allow for iterative development and accurate performance measurement. If needed, I could augment the dataset with some additional examples from social media or Gen Z slang dictionaries as long as they are in a standard input-output format.   
The essence of this project will be to use a finite-state transducer (FST) with the Pynini library, which offers simple construction and composition of weighted and unweighted FSTs in Python. Every one of the transformation rules—from normalized text to slang—will be captured as a mapping between input and output strings. For example, the mapping from "fr" to "for real" would be captured as a simple string rewrite rule with pynini.transducer("fr", "for real"). More complex mappings, such as "y'all finna" → "you all are going to", can be achieved by building multiple FSTs per component. I will explore building modular FSTs for frequent patterns and piecing them together as needed for multi-word expressions. For maintainability and scalability, I will build individual transducer modules for frequent categories like contractions, phonetic spellings, and intensifiers. The final FST will be constructed by unifying all the individual transducers into a single machine using union and closure operations. I’ll also incorporate optional epsilon transitions to allow flexibility when certain slang words may or may not appear in a sentence. The composed FST will then be compiled and optimized for use in a text normalization pipeline. To demonstrate usability, I will encapsulate the FST in a simple Python script or command-line program taking slang-laden input and returning the normalized output. As a bonus choice, I can look into encapsulating it in a chatbot or voice assistant simulation as another way to demonstrate its practical application to speech systems.  
I will compare the performance of the system on accuracy—how often it produces the correct normalized output for a given slang input. This will be done with a held-out test set of the dataset. I will also compute precision and recall if partial normalization as an option exists in some instances. I will also qualitatively examine failure cases and observe how the design of the FST factors into them.  
This project will demonstrate how FSTs can effectively handle text normalization in informal language settings, particularly for real-time voice assistant or chatbot usage. The deliverable will be a working FST for Gen Z slang normalization, an evaluation report, and insights on rule design, ambiguity resolution, and efficiency.  
