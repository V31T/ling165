{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccD5Kq24WAN3"
   },
   "source": [
    "<div style=\"text-align: right\">\n",
    "    <i>\n",
    "        LIN 5300<br>\n",
    "        Spring 2023 <br>\n",
    "        Jon Rawski <br>\n",
    "    </i>\n",
    "</div>\n",
    "\n",
    "\n",
    "# Submission Guidelines\n",
    "Please upload your completed notebook file on Canvas in the following format:\n",
    "\n",
    "LastName_FirstName_HW3.ipynb\n",
    "\n",
    "# Preliminaries (2 points)\n",
    "\n",
    "1. Load in all of the packages you will need for this assignment in the cell below. \n",
    "\n",
    "  If you load in other packages later in the notebook, be sure to bring them up here. This is good coding practice and will look cleaner for everyone when reading your code.\n",
    "\n",
    "  You will need the following:\n",
    "\n",
    "  * To load a plain text file in with the colab interface (by uploading the file to the notebook)\n",
    "  * To count occurrances of tokens\n",
    "  * A regular expression tokenizer\n",
    "  * The NLTK tokenizer for English\n",
    "  * The spaCy word tokenizer for English\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OfOQBQztFnqW"
   },
   "outputs": [],
   "source": [
    "# Load in packages that you will use in this notebook\n",
    "from pprint import pprint\n",
    "from google.colab import drive\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# put other packages you will use below this line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZSPSo-TWTxL"
   },
   "source": [
    "# Preliminaries 2 (1 point)\n",
    "\n",
    "Load in the file called `faustus.txt` in the variable `faust`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bl225PcgV61a"
   },
   "outputs": [],
   "source": [
    "#Import the file here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRL5OkT4Wn-4"
   },
   "source": [
    "# Question 1: 2 points\n",
    "\n",
    "In this section, we will be comparing different preprocessing strategies. \n",
    "\n",
    "First, tokenize the corpus using a simple regEx technique that relies on whitespaces to distinguish words (You can use the function we defined in class)!\n",
    "\n",
    "Save the resulting list into the variable `faust_regEx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nq6-78b1IGPm"
   },
   "outputs": [],
   "source": [
    "# define a tokenize function using regex based on whitespace\n",
    "\n",
    "# define a variable for each token list\n",
    "\n",
    "# print the first 10 elements as a safety check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UqHOFeVIGzB"
   },
   "source": [
    "# Question 2: 5 points\n",
    "\n",
    "Now, we are going to use the [`nltk` `word_tokenize`](https://www.kite.com/python/docs/nltk.word_tokenizefunction). You should have loaded nltk above in the very first block. Use `word_tokenize` on the corpus in a list of string arrays called `faust_nltk_tokenized`. Use a slice to print the fifth to the tenth elements of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z8oOzoHiIzdh"
   },
   "outputs": [],
   "source": [
    "# use nltk's word_tokenize function\n",
    "\n",
    "\n",
    "# save the output into a variable\n",
    "\n",
    "# print the first 10 elements as a safety check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PpfhdWSI0Me"
   },
   "source": [
    "# Question 3: 5 points\n",
    "\n",
    "Now, we are going to use the [`spacy`](https://spacy.io/usage/spacy-101) tokenization [function](https://spacy.io/api/tokenizer). \n",
    "\n",
    "The output that spacy gives you is more complicated than the output of `nltk`'s `word_tokenize` function, because the `spacy` API takes a string (e.g., \"I like cheese\") and returns a `doc` object. Within the `doc` object there are `token`s, and each `token` has a `text` object. \n",
    "\n",
    "For this question, what you need to do is:\n",
    "\n",
    "* load the spacy tokenizer with \"en\" as the default value\n",
    "* obtain the `doc` object by using the tokenizer over the list `faust_full` \n",
    "* instantiate an empty list `faust_spacy_tokenized` and implement a for loop through all of the  `token`s of the obtained doc, storing for each the `token.text` string object into your list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mTwCwQ7nM8dX"
   },
   "outputs": [],
   "source": [
    "# use spacy's tokenization features\n",
    "\n",
    "\n",
    "\n",
    "# load spacy with en as the vocabulary\n",
    "\n",
    "# get the doc object for the faust corpus\n",
    "\n",
    "\n",
    "\n",
    "# save the output into a variable\n",
    "\n",
    "# print the first 10 elements as a safety check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gLC2daI-Myn1"
   },
   "source": [
    "# Question 4: Compare tokenizations (5 points)\n",
    "\n",
    "Now that we have three tokenizations, we want to compare how similar the tokenizations are. \n",
    "\n",
    "In the code cell below, Visualize a reasonaly large subset of the corpus, tokenized under each of the three approaches above.\n",
    "Then, in the cell below that, explain how the outputs of these tokenizations differ, and what you can infer from the output about the ways the tokenization techniques differ (If necessary, you can modify the number of tokens you visualize until you converge on a good sample for the comparison). \n",
    "\n",
    "What do you think are the strengths and weaknesses of each tokenization approach? Do you think one of the tokenizations is better than another? Can you think of a way you would test which one is better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sZ7km6oRYZs"
   },
   "source": [
    "### Question 4A: Code (2/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ld_dCKjLQaqf"
   },
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CbwIX8AQm9Y"
   },
   "source": [
    "### Question 4B: Free response (3/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCVSKvDZGUDS"
   },
   "source": [
    "$\\color{red}{\\text{Put your description of the above output here. Double click in this cell to edit it. Delete this line when you are done.}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlivQPJXf6m2"
   },
   "source": [
    "# Question 5: Tabulating word counts under different algorithms (10 points)\n",
    "\n",
    "Now that you have compared and contrasted different tokenization algorithms, consider the effect that tokenization can have on our ability to characterize a corpus as a whole. \n",
    "\n",
    "Load in the `Counter` module and extract counts of all of the words under each of the three tokenizations schemes. Look at the top 5 most frequent (using the `.most_frequent()` method) and the top 10 least frequent (hint: use negative indices) words. In our data, what appear to be the biggest sources of disagreement? Do these confirm or disconfirm your hypotheses in the previous question? How or how not? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjwPTSJA_txp"
   },
   "source": [
    "### Question 5A: Code (5/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aiXEsEaVdJTB"
   },
   "outputs": [],
   "source": [
    "## Your code for question 5A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bud1U9iM_vgh"
   },
   "source": [
    "### Question 5B: Free response (5/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTWirBBEGPjO"
   },
   "source": [
    "$\\color{red}{\\text{Put your description of the above output here. Double click in this cell to edit it. Delete this line when you are done.}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FvuYyre5F_P"
   },
   "source": [
    "# Question 6: Tabulating pointwise mutual information (15 points)\n",
    "\n",
    "Mutual information is a computation that is very similar to computing a conditional probability. Recall that computing a conditional probability, defined below, requires knowing two probabilities. The first, $p(A \\cap B)$, is the probability of observing $A$ and $B$ at the same time (so observing the bigram as a type). The second, $p(A)$, is the probability of observing $A$ across all contexts.\n",
    "\n",
    "Recall that we have used MLE so to approximate all of these by their frequencies in a corpus. For example, $p(A)$ can be approximated by:\n",
    "\n",
    "<center> $\\large p(A) \\approx \\frac{count(A)}{\\sum_{w \\in V}count(w)}$ </center>\n",
    "\n",
    "Mutual information is very similar, but requires dividing the co-occurence statistic by two probabilities $p(A)$ and $p(B)$.\n",
    "\n",
    "\n",
    "<center>$\\large MI = \\frac{p(A \\cap B)}{p(A) \\cdot p(B)}$</center>\n",
    "\n",
    "<hr />\n",
    "\n",
    "\n",
    "This question contains multiple parts to respond to.\n",
    "\n",
    "1. Compute the bigram frequencies of all words in our `faustus` corpus. You may use whatever tokenization scheme you think performs the best.\n",
    "2. For each of the bigrams in that abstracts, compute the mutual information of that bigram\n",
    "3. Pick a subset of bigrams and and print their mutual information value to the notebook.\n",
    "4. Answer the questions in the free response section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pXgmepfDDAm"
   },
   "source": [
    "### Question 6A: Computing mutual information for bigrams in one sentence (10/15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PXPXWtAfCRGy"
   },
   "outputs": [],
   "source": [
    "## your code for Question 6 goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIEw6FcsdZ1f"
   },
   "source": [
    "### Question 6B: Free response (5/10 points)\n",
    "\n",
    "Characterize the different mutual information values of the subset you are looking at. What values are highest? What values are lowest? Do you think mutual information would be a better statistic to compute than a conditional probability? If so, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzshSnbtGMCo"
   },
   "source": [
    "### <font color='red'>Your written response for question 6B goes here</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCgDQrOaICRl"
   },
   "source": [
    "# Self Evaluation (5 points, added only if at least half of the previous exercises has been attempted)\n",
    "\n",
    "How do you think you did? Which parts did you struggle with the most? Which parts were easier than you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HR-uFfphYLrn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Homework_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
